{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0723d521-2cc2-47b1-a4b2-874095c7e0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67934445-364c-4149-bf7b-7627063e2671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert RLE string to a numpy array\n",
    "def rle_to_mask(rle_string, width, height):\n",
    "   \n",
    "    rows, cols = height, width\n",
    "    \n",
    "    if rle_string == -1:\n",
    "        return np.zeros((height, width))\n",
    "    else:\n",
    "        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "        img = np.zeros(rows*cols, dtype=np.uint8)\n",
    "        for index, length in rle_pairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "        img = img.reshape(cols,rows)\n",
    "        img = img.T\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a64e872-3371-4da2-b104-82c40ac79cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the pixels that delimit the edges of a region in a mask\n",
    "def get_mask_origine(mask):\n",
    "    \n",
    "    white_pixels = np.array(np.where(mask == 255))\n",
    "    first_white_pixel = white_pixels[:,0]\n",
    "    last_white_pixel = white_pixels[:,-1]\n",
    "    \n",
    "    return (first_white_pixel[1], first_white_pixel[0]), (last_white_pixel[1], last_white_pixel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3c5fb39a-0879-46d5-969f-35c2aaec3018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_single_image_bounding_box(data, imageid, image_path, img_width, img_height, resize, pixels_count):\n",
    "    \n",
    "    img_id = imageid.split('_')[0]\n",
    "    \n",
    "    img = cv2.imread(image_path + img_id + '.jpg')\n",
    "    \n",
    "    # Get RLE encoded masks of an image by its img_id and related labels (Flower, Fish...)\n",
    "    mask_filtered_byId = data[data['ImageId']==imageid]\n",
    "    img_mask = mask_filtered_byId['EncodedPixels']\n",
    "    img_mask = img_mask.values[0]\n",
    "    img_mask_label = mask_filtered_byId['Label']\n",
    "    \n",
    "    # Convert one RLE encoded mask into a binary encoded grid\n",
    "    one_mask = np.zeros((img_height, img_width))\n",
    "    one_mask = rle_to_mask(img_mask, img_width, img_height)\n",
    "    \n",
    "    # Reduce Mask size\n",
    "    one_mask = cv2.resize(one_mask, dsize=resize)\n",
    "    \n",
    "    one_mask_pixels_count = np.count_nonzero(one_mask == 255)\n",
    "    \n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(one_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    tmp_edges = []\n",
    "    for contour in contours:\n",
    "        # Get the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        tmp_edges.append({'left':x, 'top':y, 'width':w, 'height':h})\n",
    "    \n",
    "    edges = pd.DataFrame(tmp_edges)\n",
    " \n",
    "    left = edges['left'].min()\n",
    "    right = edges[['left', 'width']].sum(axis=1).max()\n",
    "    top = edges['top'].min()\n",
    "    bottom = edges[['top', 'height']].sum(axis=1).max()\n",
    "    \n",
    "    x = (left + right) / 2\n",
    "    y = (top + bottom) / 2\n",
    "    w = right - left\n",
    "    h = bottom - top\n",
    "    \n",
    "    bbox = {'X': x, 'Y': y, 'W': w, 'H': h}\n",
    "    \n",
    "    resized_img = cv2.imread(image_path + 'small/' + img_id + '.jpg')\n",
    "    \n",
    "    return imageid, bbox, one_mask, resized_img, one_mask_pixels_count, w * h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdae2db-cd4c-472d-8776-4fa115491271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A SUPPRIMER !?\n",
    "def _displayMasks(imageid, ax, masks, w, h, cmap, alpha, image_path):\n",
    "    \n",
    "    img_id = imageid.split('_')[0]\n",
    "    \n",
    "    image_path = image_path\n",
    "    img = cv2.imread(image_path + img_id + '.jpg')\n",
    "    \n",
    "    # Get RLE encoded masks of an image by its imageid and related labels (Flower, Fish...)\n",
    "    masks_filtered_byId = masks[masks['ImageId']==imageid]\n",
    "    img_masks = masks_filtered_byId['EncodedPixels'].tolist()\n",
    "    img_masks_labels = masks_filtered_byId['Label'].tolist()\n",
    "\n",
    "    # Convert RLE encoded masks into a binary encoded grids\n",
    "    all_masks = np.zeros((h, w))\n",
    "    one_mask = np.zeros((h, w))\n",
    "    mask_origines = []\n",
    "    for rle_mask in img_masks:\n",
    "        one_mask = rle_to_mask(rle_mask, w, h)\n",
    "        mask_origines.append(get_mask_origine(one_mask))\n",
    "        all_masks += one_mask\n",
    "      \n",
    "    # Displays images and related masks\n",
    "    ax.axis('off')\n",
    "\n",
    "    for origine, label in zip(mask_origines, img_masks_labels):\n",
    "        ax.annotate(text=label + \" 0\", xy=origine[0], xytext=(20, -40), xycoords='data', color='yellow', fontsize=10, fontweight='bold', textcoords='offset pixels', arrowprops=dict(arrowstyle=\"-|>\", color='yellow'))\n",
    "        ax.annotate(text=label + \" 1\", xy=origine[1], xytext=(-100, 20), xycoords='data', color='yellow', fontsize=10, fontweight='bold', textcoords='offset pixels', arrowprops=dict(arrowstyle=\"-|>\", color='yellow')) \n",
    "\n",
    "    ax.set_title(imageid)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.imshow(all_masks, cmap=cmap, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47489df8-08f2-40d5-84cc-a7cc74d2b9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displays one mask on top of its originate image\n",
    "def displayMask(imageid, ax, masks, w, h, image_path, hide_axis=False, show_mask=False):\n",
    "\n",
    "    cmap = 'viridis'\n",
    "    alpha = 0.2\n",
    "\n",
    "    img_id = imageid.split('_')[0]\n",
    "    \n",
    "    image_path = image_path\n",
    "    img = cv2.imread(image_path + img_id + '.jpg')\n",
    "\n",
    "    if show_mask:\n",
    "        # Get RLE encoded masks of an image by its imageid and related labels (Flower, Fish...)\n",
    "        masks_filtered_byId = masks[masks['ImageId']==imageid]\n",
    "        img_masks = masks_filtered_byId['EncodedPixels'].tolist()\n",
    "        img_masks_labels = masks_filtered_byId['Label'].tolist()\n",
    "    \n",
    "        # Convert RLE encoded masks into a binary encoded grids\n",
    "        all_masks = np.zeros((h, w))\n",
    "        one_mask = np.zeros((h, w))\n",
    "        mask_origines = []\n",
    "        for rle_mask in img_masks:\n",
    "            one_mask = rle_to_mask(rle_mask, w, h)\n",
    "            mask_origines.append(get_mask_origine(one_mask))\n",
    "            all_masks += one_mask\n",
    "\n",
    "    # Displays images and related masks\n",
    "    if hide_axis:\n",
    "        ax.axis('off')\n",
    "\n",
    "    if show_mask:\n",
    "        # Displays images and related masks\n",
    "        for origine, label in zip(mask_origines, img_masks_labels):\n",
    "            ax.annotate(text=label + \" 0\", xy=origine[0], xytext=(20, -40), xycoords='data', color='yellow', fontsize=10, fontweight='bold', textcoords='offset pixels', arrowprops=dict(arrowstyle=\"-|>\", color='yellow'))\n",
    "            ax.annotate(text=label + \" 1\", xy=origine[1], xytext=(-100, 20), xycoords='data', color='yellow', fontsize=10, fontweight='bold', textcoords='offset pixels', arrowprops=dict(arrowstyle=\"-|>\", color='yellow')) \n",
    "\n",
    "    ax.set_title(imageid)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "\n",
    "    if show_mask:\n",
    "        ax.imshow(all_masks, cmap=cmap, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d00e20a5-650c-4f2e-8052-0c3e299ea855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceImages(imageid, image_path, size):\n",
    "    \n",
    "    image_path = image_path\n",
    "    img = cv2.imread(image_path + imageid + '.jpg')\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "632bceee-bb8b-4f09-a6aa-2d24521974b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def displayBoundingBox(imageid, ax, x, y, w, h):\n",
    "   \n",
    "    img_id = imageid.split('_')[0]\n",
    "    im = cv2.imread('images/small/' + img_id + '.jpg')\n",
    "\n",
    "    x1 = x - w/2\n",
    "    x2 = x + w/2\n",
    "    y1 = y - h/2\n",
    "    y2 = y + h/2\n",
    "\n",
    "    #ax.axis('off')\n",
    "    ax.set_title(imageid)\n",
    "    ax.imshow(im)\n",
    "    ax.plot([x1, x2 ,x2, x1, x1],[y1, y1, y2, y2, y1],'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b32b13-c098-4b6b-b817-c3d94202a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(imageid, filepath, isTrain):\n",
    "    \n",
    "    if isTrain:\n",
    "        img_id = tf.strings.split(imageid, sep=\"_\")[0]\n",
    "    else:\n",
    "        img_id = imageid.split('_')[0]\n",
    "    \n",
    "    img = tf.io.read_file(filepath + img_id + '.jpg')\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318d010a-205c-46ae-a11b-8140d314a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def predict_image(img, model, show=False):\n",
    "\n",
    "    t0 = time.time()\n",
    "    x, y, w, h, p = model.predict(np.array([img], dtype=np.float32))[0]\n",
    "    \n",
    "    if show:\n",
    "        \n",
    "        # Dé-standardiser\n",
    "        x = x * 525\n",
    "        y = y * 350\n",
    "        w = w * 525\n",
    "        h = h * 350\n",
    "\n",
    "        x1 = x - w/2\n",
    "        x2 = x + w/2\n",
    "        y1 = y - h/2\n",
    "        y2 = y + h/2\n",
    "        \n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.plot([x1, x2 ,x2, x1, x1],[y1, y1, y2, y2, y1],'yellow')\n",
    "        plt.show()\n",
    "\n",
    "        print(x, y, w, h)\n",
    "        print(\"Execution time: \",time.time()-t0,\"secondes\")\n",
    "        print(\"Probability: \", p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e60e2a-f9a2-4ce2-b205-b7ca15f6cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markDuplicate(data, group_field, count_field):\n",
    "    g = pd.DataFrame(data.groupby([group_field]).agg({count_field:'count'}).rename({count_field:'Count'}, axis=1))\n",
    "    g.reset_index(drop=False, inplace=True)\n",
    "    l = list(g[g['Count'] > 1]['FileId'])\n",
    "    data['Multiple'] = data['FileId'].apply(lambda fieldid: True if fieldid in l else False )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6326cebe-5220-4ecf-be58-e214608b2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMaskFileFromRLE(imageid, size):\n",
    "    rle_string = df[df['ImageId']==imageid]['EncodedPixels'].tolist()[0]\n",
    "    mask_img = rle_to_mask(rle_string, 2100, 1400)\n",
    "    mask_img = cv2.resize(mask_img, dsize=size)\n",
    "    \n",
    "    \n",
    "    # Start Experience #\n",
    "    img_id = imageid.split('_')[0]\n",
    "    img = cv2.imread('images/square/' + img_id + '.jpg')\n",
    "    mask_img = np.expand_dims(mask_img, axis=-1)\n",
    "    mask_img = cv2.bitwise_and(img, img, mask=mask_img)\n",
    "    # End experience #\n",
    "    \n",
    "    #new_path = 'images/small/masks/' + imageid + '_mask.jpg'\n",
    "    new_path = 'images/square/' + imageid + '_mask.jpg'\n",
    "    if not(os.path.exists(new_path)):\n",
    "        cv2.imwrite(new_path, mask_img)\n",
    "    \n",
    "    return mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03eb5e73-9ac7-4ccc-b5b7-659db57bb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 08:46:53.800358: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def loadImages(img_id, mask_id):\n",
    "    \n",
    "    #img_filepath = 'images/small/' + img_id + '.jpg'\n",
    "    #mask_filepath = 'images/small/masks/' + mask_id + '_mask.jpg'\n",
    "    \n",
    "    img_filepath = 'images/square/' + img_id + '.jpg'\n",
    "    mask_filepath = 'images/square/' + mask_id + '_mask.jpg'\n",
    "\n",
    "    img = tf.io.read_file(img_filepath)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [350, 525])\n",
    "\n",
    "    mask = tf.io.read_file(mask_filepath)\n",
    "    mask = tf.io.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, [350, 525], method = 'nearest')\n",
    "   \n",
    "    # Normilalize\n",
    "    img = tf.cast(img, tf.float32)/255\n",
    "    mask = tf.cast(mask, tf.float32)/255\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6174f5b-b362-427b-8a9f-48a15a8d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def loadImages_square(img_id, mask_id):\n",
    "    \n",
    "    img_filepath = 'images/square/' + img_id + '.jpg'\n",
    "    mask_filepath = 'images/square/' + mask_id + '_mask.jpg'\n",
    "\n",
    "    img = tf.io.read_file(img_filepath)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "\n",
    "    mask = tf.io.read_file(mask_filepath)\n",
    "    mask = tf.io.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, [128, 128], method = 'nearest')\n",
    "   \n",
    "    # Normilalize\n",
    "    img = tf.cast(img, tf.float32)/255\n",
    "    mask = tf.cast(mask, tf.float32)/255\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ab8dfc-0497-4aa5-a507-42cd560748cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Image pixels with Mask and return statistics\n",
    "def filterWithMask(imageid, dataset, w, h, image_path, show=False):\n",
    "    \n",
    "    img_id = imageid.split('_')[0]\n",
    "    img = cv2.imread(image_path + img_id + '.jpg')\n",
    "    \n",
    "    dataset = dataset[dataset['ImageId']==imageid]\n",
    "    rle = dataset['EncodedPixels'].values[0]\n",
    "    label = dataset['Label'].values[0]\n",
    "\n",
    "    one_mask = rle_to_mask(rle, w, h)\n",
    "\n",
    "    indices = np.argwhere(one_mask == 255)\n",
    "    selected_pixels = img[indices[:, 0], indices[:, 1]]\n",
    "\n",
    "    mean_value = np.mean(selected_pixels)\n",
    "    std_value = np.std(selected_pixels)\n",
    "\n",
    "    if show:\n",
    "        one_mask = np.expand_dims(one_mask, axis=-1)\n",
    "        new_img = np.where(one_mask == 255, img, 0)\n",
    "        \n",
    "        plt.imshow(new_img)\n",
    "        plt.title(imageid)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return round(mean_value, 2), round(std_value, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a19177-6997-4b5e-a816-9b736441d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-significant pixels\n",
    "def countNonSignificantPixels(imageid, image_path, show=False):\n",
    "    \n",
    "    img_id = imageid.split('_')[0]\n",
    "    img = cv2.imread(image_path + img_id + '.jpg')\n",
    "\n",
    "    # Images couleur converties en niveaux de gris\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Images en niveaux de gris converties en imahges binaires\n",
    "    _, binary_img = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    black_pixel_count = img.size - cv2.countNonZero(binary_img)\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return black_pixel_count, round(black_pixel_count / img.size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269d7c1-0c86-4704-8e05-88d6e073258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImages(ImageIds, grid_x, grid_y, df, img_width, img_height, image_path, hide_axis=True, show_mask=False):\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_x, grid_y, figsize=(20, 10), layout='constrained')\n",
    "    for axe, img_id in zip(axes.flat, ImageIds):\n",
    "        displayMask(img_id, axe, df, img_width, img_height, image_path, hide_axis, show_mask)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
