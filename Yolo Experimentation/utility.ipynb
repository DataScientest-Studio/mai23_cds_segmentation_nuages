{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0723d521-2cc2-47b1-a4b2-874095c7e0d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import urllib, json\n",
    "import matplotlib.lines as lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba61d92f-8cb7-47a9-9f0d-d953c392e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_SHAPE = (8, 8)\n",
    "RESIZE_VALUE = (256, 256)\n",
    "IMAGES_PATH = 'images/'\n",
    "RESIZED_PATH = 'images/resized/'\n",
    "CLASSES = ['Fish', 'Flower', 'Gravel', 'Sugar']\n",
    "ORIGINAL_IMAGE_WIDTH = 2100\n",
    "ORIGINAL_IMAGE_HEIGHT = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c491af1a-ce32-475c-b6d4-c0374db2acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBoundingBox(data, resizeValue):\n",
    "\n",
    "    boxes = []\n",
    "    for imageid in tqdm(data['Image_Label']):\n",
    "        imageid, bbox, mask_pixels_count, box_pixels_count = getImageBoundingBox(data, imageid, IMAGES_PATH, ORIGINAL_IMAGE_WIDTH, ORIGINAL_IMAGE_HEIGHT, resizeValue)\n",
    "        boxes.append(\n",
    "            {\n",
    "                'Image_Label': imageid, \n",
    "                'XMOY': bbox['XMOY'], \n",
    "                'YMOY': bbox['YMOY'], \n",
    "                'W': bbox['W'], \n",
    "                'H': bbox['H'], \n",
    "                'ResizedMaskPixelsCount': mask_pixels_count, \n",
    "                'ResizedBoundingBoxPixelsCount': box_pixels_count, \n",
    "                'BoxMaskGap': (box_pixels_count - mask_pixels_count) / mask_pixels_count if mask_pixels_count != 0 else 0\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    bounding_boxes = pd.DataFrame(boxes)\n",
    "    \n",
    "    return data.merge(right=bounding_boxes, on='Image_Label', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84890e4f-7cb6-4665-b0fb-e45220cf7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageBoundingBox(data, imageid, image_path, img_width, img_height, size, resize=True):\n",
    "    \n",
    "    # Get RLE encoded masks of an image by its imageid and related labels (Flower, Fish...)\n",
    "    mask_filtered_byId = data[data['Image_Label']==imageid]\n",
    "    img_mask = mask_filtered_byId['EncodedPixels']\n",
    "\n",
    "    if np.sum(mask_filtered_byId['EncodedPixelsCount']) != 0:\n",
    "        \n",
    "        img_mask = img_mask.values[0]\n",
    "        \n",
    "        # Convert one RLE encoded mask into a binary encoded grid\n",
    "        one_mask = np.zeros((img_height, img_width))\n",
    "        one_mask = rle_to_mask(img_mask, img_width, img_height)\n",
    "        \n",
    "        # Resize Mask size\n",
    "        if resize:\n",
    "            one_mask = cv2.resize(one_mask, dsize=size)\n",
    "        \n",
    "        one_mask_pixels_count = np.count_nonzero(one_mask == 255)\n",
    "        \n",
    "        # Find contours in the binary mask\n",
    "        contours, _ = cv2.findContours(one_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "        tmp_edges = []\n",
    "        for contour in contours:\n",
    "            # Get the bounding box of the contour\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            tmp_edges.append({'left':x, 'top':y, 'width':w, 'height':h})\n",
    "        \n",
    "        edges = pd.DataFrame(tmp_edges)\n",
    "     \n",
    "        left = edges['left'].min()\n",
    "        right = edges[['left', 'width']].sum(axis=1).max()\n",
    "        top = edges['top'].min()\n",
    "        bottom = edges[['top', 'height']].sum(axis=1).max()\n",
    "        \n",
    "        XMOY = (left + right) / 2\n",
    "        YMOY = (top + bottom) / 2\n",
    "        W = right - left\n",
    "        H = bottom - top\n",
    "        \n",
    "        bbox = {'XMOY': XMOY, 'YMOY': YMOY, 'W': W, 'H': H}\n",
    "        \n",
    "        return imageid, bbox, one_mask_pixels_count, w * h\n",
    "    \n",
    "    else:\n",
    "        bbox = {'XMOY': 0, 'YMOY': 0, 'W': 0, 'H': 0}\n",
    "        \n",
    "        return imageid, bbox, 0, 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53160db7-10ba-496e-a549-0dda0b325223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertit les coordonnées normalisées de la bbox vers d'autres coordonnées dans le repère d'une case de la grille\n",
    "def convert_target(target, output_shape=OUTPUT_SHAPE, nb_classes=4):\n",
    "    \n",
    "    y_target = np.zeros([output_shape[0], output_shape[1], 1 + 4 + nb_classes])\n",
    "    lx = 1 / output_shape[1]\n",
    "    ly = 1 / output_shape[0]\n",
    "    \n",
    "    for x, y, w, h, fish, flower, gravel, sugar  in [target]:\n",
    "\n",
    "        idx_x = int(x//lx)\n",
    "        idx_y = int(y//ly)\n",
    "        \n",
    "        y_target[idx_y, idx_x, 0] = 1 if np.sum([x, y, w, h]) != 0 else 0 # Presence of object\n",
    "        y_target[idx_y, idx_x, 1] = 2 * (x / lx - (idx_x + 0.5)) # Coordinate x\n",
    "        y_target[idx_y, idx_x, 2] = 2 * (y / ly - (idx_y + 0.5)) # Coordinate y\n",
    "        y_target[idx_y, idx_x, 3] = w # Coordinate w\n",
    "        y_target[idx_y, idx_x, 4] = h # Coordinate h\n",
    "        y_target[idx_y, idx_x, 5] = fish\n",
    "        y_target[idx_y, idx_x, 6] = flower\n",
    "        y_target[idx_y, idx_x, 7] = gravel\n",
    "        y_target[idx_y, idx_x, 8] = sugar\n",
    "\n",
    "        \n",
    "    return y_target.reshape([-1, 1 + 4 + nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c6f736-ddaf-40f8-b14f-70d99b384600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les sorties du modèle sont réinterpretées à l'aide des activateurs qui correspondent au type de la sortie\n",
    "# Les données sont interpretable par l'humain\n",
    "def transform_netout(y_pred_raw):\n",
    "\n",
    "    # outputs sigmoïde [0,1] et notre p_true doit valoir 0 ou 1 \n",
    "    y_pred_conf = tf.sigmoid(y_pred_raw[..., :1])\n",
    "\n",
    "    # pour avoir des valeurs comprises entre -1 et 1 avec tanh --> rappel: chaque case de la grille devient un nouveau repère dont l'origine est centrée: le max des abcisses et des ordonnées est 1 et le min -1\n",
    "    y_pred_xy = (tf.nn.tanh(y_pred_raw[..., 1:3]))\n",
    "    \n",
    "    # parce que la largeur et la hauteur de la bbox peuvent valoir 0 au min et 1 au max\n",
    "    y_pred_wh = tf.sigmoid(y_pred_raw[..., 3:5])\n",
    "\n",
    "    # pour avoir des probas comprises entre 0 et 1 pour chacune des 4 classes\n",
    "    y_pred_class = tf.nn.softmax(y_pred_raw[..., 5:])    \n",
    "    #y_pred_class = tf.sigmoid(y_pred_raw[..., 5:])    \n",
    "\n",
    "    return tf.concat([y_pred_conf, y_pred_xy, y_pred_wh, y_pred_class], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74be9591-2dce-4271-bf42-1613e4e3cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_image(filepath, y, resize=RESIZE_VALUE):\n",
    "    \n",
    "#     img = tf.io.read_file(RESIZED_PATH + filepath)\n",
    "#     img = tf.image.decode_png(img, channels=3)\n",
    "#     img = tf.image.resize(img, resize)\n",
    "\n",
    "#     return img, convert_target(y.numpy().copy(), OUTPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34790b47-f714-4cc2-8b96-cea4e9320e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filepath, y, resize=RESIZE_VALUE):\n",
    "    \n",
    "    im = tf.io.read_file(RESIZED_PATH + filepath)\n",
    "    im = tf.image.decode_png(im, channels=3)\n",
    "    im = tf.image.resize(im, resize)\n",
    "    \n",
    "    tx_max = resize[1] * tf.nn.relu(y[0] - y[2]/2)\n",
    "    tx_min = -resize[1] * tf.nn.relu(1 - y[0] - y[2]/2)\n",
    "    ty_max = resize[0] * tf.nn.relu(y[1] - y[3]/2)\n",
    "    ty_min = -resize[0] * tf.nn.relu(1 - y[1] - y[3]/2)\n",
    "    \n",
    "    tx = np.random.uniform(tx_min, tx_max)\n",
    "    ty = np.random.uniform(ty_min, ty_max)\n",
    "    \n",
    "    im = tf.keras.preprocessing.image.apply_affine_transform(\n",
    "        im.numpy(), \n",
    "        theta=0, \n",
    "        tx=ty, ty=tx, \n",
    "        shear=0, \n",
    "        zx=1, zy=1, \n",
    "        row_axis=0, col_axis=1, \n",
    "        channel_axis=2, fill_mode='nearest', cval=0.0, order=1\n",
    "    )\n",
    "    \n",
    "    y_new = y.numpy().copy()\n",
    "    y_new[0] += -tx/resize[1]\n",
    "    y_new[1] += -ty/resize[0]\n",
    "    \n",
    "    return im, convert_target(y_new, OUTPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d26b1d-3748-4d47-a53f-ee5ed19ca504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_loss(y_true, y_pred):\n",
    "    \n",
    "    y_true_conf = y_true[..., 0] # Vecteur de présence d'un objet\n",
    "    y_true_class = y_true[..., 5:] # Probabilité conditionelle des vrais objets\n",
    "    y_pred_class = y_pred[..., 5:] # Probabilité conditionelle des prédictions\n",
    "    \n",
    "    # Calcul de la fonction de perte\n",
    "    class_loss = tf.reduce_sum(y_true_conf * tf.reduce_sum(tf.square(y_true_class - y_pred_class), axis = -1), axis = -1)\n",
    "    \n",
    "    return class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3e9a8fa-6d41-4aff-9b60-b973a2150142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_loss(y_true, y_pred):\n",
    "    \n",
    "    # Probabilty of object presence\n",
    "    y_true_conf = y_true[..., 0]\n",
    "    \n",
    "    # x and y loss for real object\n",
    "    y_true_xy = y_true[..., 1:3]\n",
    "    y_pred_xy = y_pred[..., 1:3]\n",
    "    xy_loss = tf.reduce_sum(tf.reduce_sum(tf.square(y_true_xy - y_pred_xy), axis =- 1) * y_true_conf, axis = -1)\n",
    "    \n",
    "    # w and h loss for real object\n",
    "    y_true_wh = y_true[..., 3:5]\n",
    "    y_pred_wh = y_pred[..., 3:5]\n",
    "    wh_loss = tf.reduce_sum(tf.reduce_sum(tf.square(tf.sqrt(y_true_wh) - tf.sqrt(y_pred_wh)), axis = -1) * y_true_conf, axis = -1)\n",
    "    \n",
    "    return xy_loss + wh_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba438b03-8989-4d75-a48e-6280e3fc2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_noobj = 0.5\n",
    "\n",
    "def object_loss(y_true, y_pred):\n",
    "    \n",
    "    # x and y loss for real object\n",
    "    y_true_p = y_true[..., 0]\n",
    "    y_pred_p = y_pred[..., 0]\n",
    "    \n",
    "    return tf.reduce_sum((lambda_noobj + (1 - lambda_noobj) * y_true_p) * tf.square(y_true_p - y_pred_p), axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c2320b-6fb9-4947-89c1-a0896f436b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_coord = 5\n",
    "lambda_object = 1\n",
    "lambda_class = 1\n",
    "\n",
    "def global_loss(y_true, y_pred):\n",
    "    \n",
    "    # Convert input\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_pred = transform_netout(y_pred)\n",
    "    \n",
    "    loss_coordinate = coord_loss(y_true, y_pred)\n",
    "    loss_object = object_loss(y_true, y_pred)\n",
    "    loss_class = class_loss(y_true, y_pred)\n",
    "    \n",
    "    return lambda_object * loss_object + lambda_coord * loss_coordinate + lambda_class * loss_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799dbc32-df10-4060-a25f-0f22a321a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    \n",
    "    resp = urllib.request.urlopen(url) \n",
    "    img = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    img = cv2.imdecode(img, -1)\n",
    "    img = cv2.resize(img, RESIZE_VALUE)\n",
    "    img = img[..., [2,1,0]]\n",
    "    \n",
    "    return tf.keras.applications.efficientnet.preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb0479c-f6cb-4371-8858-4c0a8b9fdb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bounding_box(im, bbox, class_pred, ax, normalised=True, color='r'):\n",
    "    \n",
    "    # Signification de bbox\n",
    "    x, y, w, h, fish, flower, gravel, sugar = bbox\n",
    "    \n",
    "    # Convertir les cordonées (x,y,w,h) en (x1,x2,y1,y2)\n",
    "    x1 = x - w / 2\n",
    "    x2 = x + w / 2\n",
    "    y1 = y - h / 2\n",
    "    y2 = y + h / 2\n",
    "    \n",
    "    # redimensionner en cas de normalisation\n",
    "    if normalised:\n",
    "        x1 = x1 * im.shape[1]\n",
    "        x2 = x2 * im.shape[1]\n",
    "        y1 = y1 * im.shape[0]\n",
    "        y2 = y2 * im.shape[0]\n",
    "\n",
    "    delta_x = 2\n",
    "    delta_y = 7\n",
    "    if y1 - delta_y < 0:\n",
    "        delta_y_resolved = y1 + delta_y\n",
    "    else:\n",
    "        delta_y_resolved = y1 - delta_y\n",
    "\n",
    "    ax.text(x1 + delta_x, delta_y_resolved, class_pred, fontsize=10, ha='left', va='center', bbox=dict(boxstyle='square', alpha=0.8, facecolor='orange', edgecolor='none'))\n",
    "    \n",
    "    # Afficher l'image\n",
    "    ax.set_title(class_pred)\n",
    "    ax.imshow(im)\n",
    "    \n",
    "    # Afficher la bounding box\n",
    "    ax.plot([x1, x2, x2, x1, x1],[y1, y1, y2, y2, y1], 'orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e58d7a64-2f6e-4a7d-a4eb-7df48e8de362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_yolo_grid(g):\n",
    "    \n",
    "    c_x = tf.cast(tf.reshape(tf.tile(tf.range(g), [g]), (1, g, g)), 'float32')\n",
    "    c_y = tf.transpose(c_x, (0,2,1))\n",
    "    \n",
    "    return tf.stack([tf.reshape(c_x, (-1, g*g)), tf.reshape(c_y, (-1, g*g))] , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db00259-4747-4fac-9781-b70fa4417e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 00:40:58.278330: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-13 00:40:58.278476: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "c_grid = generate_yolo_grid(OUTPUT_SHAPE[0])\n",
    "\n",
    "def proccess_xy(y_true_raw):\n",
    "\n",
    "    y_true_conf = y_true_raw[..., :1]\n",
    "    y_true_xy = ((y_true_raw[..., 1:3] + 1) / 2 + c_grid) / OUTPUT_SHAPE[0]\n",
    "    y_true_wh = y_true_raw[..., 3:5]\n",
    "    y_true_class = y_true_raw[..., 5:]\n",
    "    \n",
    "    return tf.concat([y_true_conf, y_true_xy, y_true_wh, y_true_class], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2de391-9ee9-489f-b925-5e03ef696b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_bboxes(y, threshold=0.3):\n",
    "    \n",
    "    y_xy = tf.cast(y, tf.float32)\n",
    "    y_xy = tf.expand_dims(y_xy, axis=0)\n",
    "    y_xy = proccess_xy(y_xy)[0]\n",
    "    \n",
    "    bboxes =  sorted(y_xy.numpy(), key=lambda x: x[0], reverse=True)\n",
    "    bboxes = np.array(bboxes)\n",
    "    result = bboxes[bboxes[:,0] > threshold]\n",
    "    \n",
    "    if len(result)== 0:\n",
    "        return bboxes[[0]]\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f447f5ae-d916-4499-805f-7285d8c2293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(img, model, ax, threshold=0.8):\n",
    "    \n",
    "    pred = model(np.array([img], dtype=np.float32))[0]\n",
    "\n",
    "    # Interpretation des résultats du modèle\n",
    "    pred = transform_netout(pred)\n",
    "\n",
    "    # On sélectionne dans la grille, les préductions (une case) avec l'indice de confiance (PObject) > threshold ou à défaut le plus haut\n",
    "    bboxes_pred = pred_bboxes(pred, threshold)\n",
    "    \n",
    "    class_pred = CLASSES[np.argmax(bboxes_pred[0, 5:])]\n",
    "    box_prob = round(bboxes_pred[0, 0] * 100, 2)\n",
    "    class_prob = round(max(bboxes_pred[0, 5:]) * 100, 2)\n",
    "\n",
    "    plot_title = class_pred + \": \" + str(class_prob) + \" % - Bbox: \" + str(box_prob) + \" %\"\n",
    "    \n",
    "    for bbox in bboxes_pred:\n",
    "        bbox = bbox[1:]\n",
    "        show_bounding_box(img/255, bbox, plot_title, ax)\n",
    "    \n",
    "    return bboxes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97a7c363-f3a8-4fb3-9196-20190d9405cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    \n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_pred = transform_netout(y_pred)\n",
    "\n",
    "    xmoy_true = y_true[..., 1:2]\n",
    "    ymoy_true = y_true[..., 2:3]\n",
    "    w_true = y_true[..., 3:4]\n",
    "    h_true = y_true[..., 4:5]\n",
    "    \n",
    "    xmoy_pred = y_pred[..., 1:2]\n",
    "    ymoy_pred = y_pred[..., 2:3]\n",
    "    w_pred = y_pred[..., 3:4]\n",
    "    h_pred = y_pred[..., 4:5]\n",
    "\n",
    "    x1_true = xmoy_true - w_true / 2\n",
    "    x2_true = xmoy_true + w_true / 2\n",
    "    y1_true = ymoy_true - h_true / 2\n",
    "    y2_true = ymoy_true + h_true / 2\n",
    "\n",
    "    x1_pred = xmoy_pred - w_pred / 2\n",
    "    x2_pred = xmoy_pred + w_pred / 2\n",
    "    y1_pred = ymoy_pred - h_pred / 2\n",
    "    y2_pred = ymoy_pred + h_pred / 2\n",
    "\n",
    "    x1 = tf.math.maximum(x1_true, x1_pred)\n",
    "    y1 = tf.math.maximum(y1_true, y1_pred)\n",
    "    x2 = tf.math.minimum(x2_true, x2_pred)\n",
    "    y2 = tf.math.minimum(y2_true, y2_pred)\n",
    "\n",
    "    intersection = tf.maximum(x2 - x1, 0) * tf.maximum(y2 - y1, 0)\n",
    "    area_true = w_true * h_true\n",
    "    area_pred = w_pred * h_pred\n",
    "\n",
    "    iou = intersection / (area_true + area_pred - intersection + 1e-6)\n",
    "  \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47489df8-08f2-40d5-84cc-a7cc74d2b9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displays one mask on top of its originate image\n",
    "def show_ground(image_label, ax, masks, w, h, image_path, hide_axis=False, show_mask=False):\n",
    "\n",
    "    alpha = 0.2\n",
    "\n",
    "    filename = image_label.split('_')[0]\n",
    "    \n",
    "    image_path = image_path\n",
    "    img = cv2.imread(image_path + filename)\n",
    "\n",
    "    if show_mask:\n",
    "        # Get RLE encoded masks of an image by its image_label and related labels (Flower, Fish...)\n",
    "        masks_filtered_byId = masks[masks['Image_Label']==image_label]\n",
    "        img_masks = masks_filtered_byId['EncodedPixels'].tolist()\n",
    "        img_masks_labels = masks_filtered_byId['Label'].tolist()\n",
    "    \n",
    "        # Convert RLE encoded masks into a binary encoded grids\n",
    "        all_masks = np.zeros((h, w))\n",
    "        one_mask = np.zeros((h, w))\n",
    "        mask_origines = []\n",
    "        for rle_mask in img_masks:\n",
    "            one_mask = rle_to_mask(rle_mask, w, h)\n",
    "            mask_origines.append(get_mask_origine(one_mask))\n",
    "            all_masks += one_mask\n",
    "\n",
    "    # Displays images and related masks\n",
    "    if hide_axis:\n",
    "        ax.axis('off')\n",
    "\n",
    "    if show_mask:\n",
    "        # Displays images and related masks\n",
    "        for origine, label in zip(mask_origines, img_masks_labels):\n",
    "            ax.annotate(text=label + \" 0\", xy=origine[0], xytext=(20, -30), xycoords='data', color='yellow', fontsize=10, fontweight='bold', textcoords='offset pixels')\n",
    "            ax.annotate(text=label + \" 1\", xy=origine[1], xytext=(-90, 20), xycoords='data', color='yellow', fontsize=10, fontweight='bold', textcoords='offset pixels') \n",
    "\n",
    "        cross_size = 75\n",
    "        cross_0_x = mask_origines[0][0][0]\n",
    "        cross_0_y = mask_origines[0][0][1]\n",
    "        cross_1_x = mask_origines[0][1][0]\n",
    "        cross_1_y = mask_origines[0][1][1]\n",
    "        \n",
    "        cross_0_line1 = lines.Line2D([cross_0_x, cross_0_x], [cross_0_y - cross_size, cross_0_y + cross_size], color='y')\n",
    "        cross_0_line2 = lines.Line2D([cross_0_x - cross_size, cross_0_x + cross_size], [cross_0_y, cross_0_y], color='y')\n",
    "        cross_1_line1 = lines.Line2D([cross_1_x, cross_1_x], [cross_1_y - cross_size, cross_1_y + cross_size], color='y')\n",
    "        cross_1_line2 = lines.Line2D([cross_1_x - cross_size, cross_1_x + cross_size], [cross_1_y, cross_1_y], color='y')\n",
    "    \n",
    "        # # Add the cross lines to the plot\n",
    "        ax.add_line(cross_0_line1)\n",
    "        ax.add_line(cross_0_line2)\n",
    "        ax.add_line(cross_1_line1)\n",
    "        ax.add_line(cross_1_line2)\n",
    "        ###\n",
    "    \n",
    "    ax.set_title(image_label)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "\n",
    "    if show_mask:\n",
    "        ax.imshow(all_masks, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b59117f8-366a-4410-8b71-92b709929cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-significant pixels (100% black pixels contained in the black bar)\n",
    "def countNonSignificantPixels(imageid, image_path, show=False):\n",
    "\n",
    "    fileName = imageid.split('_')[0]\n",
    "    img = cv2.imread(image_path + fileName)\n",
    "\n",
    "    # Images couleur converties en niveaux de gris\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Images en niveaux de gris converties en imahges binaires\n",
    "    _, binary_img = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    black_pixel_count = img.size - cv2.countNonZero(binary_img)\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return black_pixel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e713e4ea-ce86-45db-bd64-e75604c8b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBlackStripesOverlapInfo(imageid, image_path, data, width, height):\n",
    "\n",
    "    data_filtered_byId = data[data['Image_Label']==imageid]\n",
    "    \n",
    "    if np.sum(data_filtered_byId['EncodedPixelsCount']) != 0:\n",
    "    \n",
    "        # Get initial image\n",
    "        fileName = imageid.split('_')[0]\n",
    "        img = cv2.imread(image_path + fileName)\n",
    "    \n",
    "        # Detect black bar\n",
    "        if len(img.shape) == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, blackMask = cv2.threshold(img, 1, 255, cv2.THRESH_BINARY_INV)\n",
    "        black_pixel_count = img.size - cv2.countNonZero(blackMask)\n",
    "    \n",
    "        # Get Bounding Box outline\n",
    "        bbox = data[data['Image_Label']== imageid][['XMOY','YMOY','W','H']].values[0]\n",
    "        x1 = bbox[0] - bbox[2]/2\n",
    "        x2 = bbox[0] + bbox[2]/2\n",
    "        y1 = bbox[1] - bbox[3]/2\n",
    "        y2 = bbox[1] + bbox[3]/2\n",
    "    \n",
    "        # Get Bounding Box mask\n",
    "        bboxMask = np.zeros((height, width, 1), dtype=np.uint8)  # Grayscale image, initialized with zeros\n",
    "        \n",
    "        x1, x2 = int(x1), int(x2)\n",
    "        y1, y2 = int(y1), int(y2)\n",
    "        \n",
    "        # Fill the inner area of the rectangle with white pixels\n",
    "        bboxMask[y1:y2, x1:x2] = 255\n",
    "    \n",
    "        intersectMask = cv2.bitwise_and(bboxMask, blackMask)\n",
    "        intersectPixelsCount = np.sum(intersectMask == 255)\n",
    "        bboxMaskPixelsCount = np.sum(bboxMask == 255)\n",
    "        \n",
    "        return img, bboxMask, blackMask, intersectMask, intersectPixelsCount, bboxMaskPixelsCount, round(intersectPixelsCount / bboxMaskPixelsCount, 10)\n",
    "    \n",
    "    else:\n",
    "        return None, None, None, None, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "110f458f-140e-4002-a450-246d385173eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertEndocedToArray(x):\n",
    "    if x == -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.array(x.split(' ')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c475ad4a-c7d0-4c7c-9efd-98380c10c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countEncodedPixels(x):\n",
    "    if np.sum(x) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sum(x.reshape(int(np.size(x)/2), 2)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311405a-8492-4fae-994a-211053abdecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2e32a-5851-4374-b457-5982ce3c5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b7180-8195-420b-9db0-10fd9982cd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794c04b-ffff-410e-a664-618cb4185049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a10e14-dfe2-45a1-b820-3f421020d321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f9ce7c-a647-40d6-ab5e-959b46739747",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# EVERYTHING BELOW TO BE REVIEWED #\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7bb2b-ae61-413a-955e-d106d9f64d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "962bb2ab-9a7f-4060-80d8-313ae08f419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize a unique image\n",
    "def resizeImage(sourcePath, fileName, size):\n",
    "\n",
    "    img_resized = None\n",
    "    \n",
    "    img = cv2.imread(sourcePath + fileName)\n",
    "\n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, dsize=size)\n",
    "\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4ba8642-7966-4296-9e9a-8764e5b3d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the content of a source folder and save the result to the target folder\n",
    "def resizeImagesFromFolder(sourcePath, targetPath, size):\n",
    "\n",
    "    folderContent = os.listdir(sourcePath)\n",
    "\n",
    "    filesName = [item for item in folderContent if os.path.isfile(os.path.join(sourcePath, item))]\n",
    "\n",
    "    for fName in tqdm(filesName):\n",
    "        resizedImage = resizeImage(sourcePath, fName, size)\n",
    "        if resizedImage is not None:\n",
    "            targetFilePath = targetPath + fName\n",
    "            cv2.imwrite(targetFilePath, resizedImage)\n",
    "                \n",
    "    return len(filesName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67934445-364c-4149-bf7b-7627063e2671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert RLE string to a numpy array\n",
    "def rle_to_mask(rle_string, width, height):\n",
    "   \n",
    "    rows, cols = height, width\n",
    "    \n",
    "    if rle_string == -1:\n",
    "        return np.zeros((height, width))\n",
    "    else:\n",
    "        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "        img = np.zeros(rows*cols, dtype=np.uint8)\n",
    "        for index, length in rle_pairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "        img = img.reshape(cols,rows)\n",
    "        img = img.T\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caabb302-c336-496f-973a-a1cbae082abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Image pixels with Mask (we get the cloud pixels inside the mask) and return statistics\n",
    "def filterWithMask(imageid, dataset, w, h, image_path, show=False):\n",
    "    \n",
    "    img_id = imageid.split('_')[0]\n",
    "    img = cv2.imread(image_path + img_id + '.jpg')\n",
    "    \n",
    "    dataset = dataset[dataset['ImageId']==imageid]\n",
    "    rle = dataset['EncodedPixels'].values[0]\n",
    "    label = dataset['Label'].values[0]\n",
    "\n",
    "    one_mask = rle_to_mask(rle, w, h)\n",
    "\n",
    "    indices = np.argwhere(one_mask == 255)\n",
    "    selected_pixels = img[indices[:, 0], indices[:, 1]]\n",
    "\n",
    "    mean_value = np.mean(selected_pixels)\n",
    "    std_value = np.std(selected_pixels)\n",
    "\n",
    "    if show:\n",
    "        one_mask = np.expand_dims(one_mask, axis=-1)\n",
    "        new_img = np.where(one_mask == 255, img, 0)\n",
    "        \n",
    "        plt.imshow(new_img)\n",
    "        plt.title(imageid)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return round(mean_value, 2), round(std_value, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a64e872-3371-4da2-b104-82c40ac79cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the pixels that delimit the edges of a region in a mask\n",
    "def get_mask_origine(mask):\n",
    "    \n",
    "    white_pixels = np.array(np.where(mask == 255))\n",
    "    first_white_pixel = white_pixels[:,0]\n",
    "    last_white_pixel = white_pixels[:,-1]\n",
    "    \n",
    "    return (first_white_pixel[1], first_white_pixel[0]), (last_white_pixel[1], last_white_pixel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "632bceee-bb8b-4f09-a6aa-2d24521974b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def displayBoundingBox(imageid, ax, x, y, w, h):\n",
    "   \n",
    "    img_id = imageid.split('_')[0]\n",
    "    im = cv2.imread('images/small/' + img_id + '.jpg')\n",
    "\n",
    "    x1 = x - w/2\n",
    "    x2 = x + w/2\n",
    "    y1 = y - h/2\n",
    "    y2 = y + h/2\n",
    "\n",
    "    #ax.axis('off')\n",
    "    ax.set_title(imageid)\n",
    "    ax.imshow(im)\n",
    "    ax.plot([x1, x2 ,x2, x1, x1],[y1, y1, y2, y2, y1],'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9b32b13-c098-4b6b-b817-c3d94202a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_image(imageid, filepath, isTrain):\n",
    "    \n",
    "#     if isTrain:\n",
    "#         img_id = tf.strings.split(imageid, sep=\"_\")[0]\n",
    "#     else:\n",
    "#         img_id = imageid.split('_')[0]\n",
    "    \n",
    "#     img = tf.io.read_file(filepath + img_id + '.jpg')\n",
    "#     img = tf.image.decode_png(img, channels=3)\n",
    "    \n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "318d010a-205c-46ae-a11b-8140d314a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def predict_image(img, model, show=False):\n",
    "\n",
    "    t0 = time.time()\n",
    "    x, y, w, h, p = model.predict(np.array([img], dtype=np.float32))[0]\n",
    "    \n",
    "    if show:\n",
    "        \n",
    "        # Dé-standardiser\n",
    "        x = x * 525\n",
    "        y = y * 350\n",
    "        w = w * 525\n",
    "        h = h * 350\n",
    "\n",
    "        x1 = x - w/2\n",
    "        x2 = x + w/2\n",
    "        y1 = y - h/2\n",
    "        y2 = y + h/2\n",
    "        \n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.plot([x1, x2 ,x2, x1, x1],[y1, y1, y2, y2, y1],'yellow')\n",
    "        plt.show()\n",
    "\n",
    "        print(x, y, w, h)\n",
    "        print(\"Execution time: \",time.time()-t0,\"secondes\")\n",
    "        print(\"Probability: \", p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46e60e2a-f9a2-4ce2-b205-b7ca15f6cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markDuplicate(data, group_field, count_field):\n",
    "    g = pd.DataFrame(data.groupby([group_field]).agg({count_field:'count'}).rename({count_field:'Count'}, axis=1))\n",
    "    g.reset_index(drop=False, inplace=True)\n",
    "    l = list(g[g['Count'] > 1]['FileId'])\n",
    "    data['Multiple'] = data['FileId'].apply(lambda fieldid: True if fieldid in l else False )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6326cebe-5220-4ecf-be58-e214608b2edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMaskFileFromRLE(imageid, size):\n",
    "    rle_string = df[df['ImageId']==imageid]['EncodedPixels'].tolist()[0]\n",
    "    mask_img = rle_to_mask(rle_string, 2100, 1400)\n",
    "    mask_img = cv2.resize(mask_img, dsize=size)\n",
    "    \n",
    "    \n",
    "    # Start Experience #\n",
    "    img_id = imageid.split('_')[0]\n",
    "    img = cv2.imread('images/square/' + img_id + '.jpg')\n",
    "    mask_img = np.expand_dims(mask_img, axis=-1)\n",
    "    mask_img = cv2.bitwise_and(img, img, mask=mask_img)\n",
    "    # End experience #\n",
    "    \n",
    "    #new_path = 'images/small/masks/' + imageid + '_mask.jpg'\n",
    "    new_path = 'images/square/' + imageid + '_mask.jpg'\n",
    "    if not(os.path.exists(new_path)):\n",
    "        cv2.imwrite(new_path, mask_img)\n",
    "    \n",
    "    return mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03eb5e73-9ac7-4ccc-b5b7-659db57bb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def loadImages(img_id, mask_id):\n",
    "    \n",
    "    #img_filepath = 'images/small/' + img_id + '.jpg'\n",
    "    #mask_filepath = 'images/small/masks/' + mask_id + '_mask.jpg'\n",
    "    \n",
    "    img_filepath = 'images/square/' + img_id + '.jpg'\n",
    "    mask_filepath = 'images/square/' + mask_id + '_mask.jpg'\n",
    "\n",
    "    img = tf.io.read_file(img_filepath)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [350, 525])\n",
    "\n",
    "    mask = tf.io.read_file(mask_filepath)\n",
    "    mask = tf.io.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, [350, 525], method = 'nearest')\n",
    "   \n",
    "    # Normilalize\n",
    "    img = tf.cast(img, tf.float32)/255\n",
    "    mask = tf.cast(mask, tf.float32)/255\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6174f5b-b362-427b-8a9f-48a15a8d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def loadImages_square(img_id, mask_id):\n",
    "    \n",
    "    img_filepath = 'images/square/' + img_id + '.jpg'\n",
    "    mask_filepath = 'images/square/' + mask_id + '_mask.jpg'\n",
    "\n",
    "    img = tf.io.read_file(img_filepath)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "\n",
    "    mask = tf.io.read_file(mask_filepath)\n",
    "    mask = tf.io.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, [128, 128], method = 'nearest')\n",
    "   \n",
    "    # Normilalize\n",
    "    img = tf.cast(img, tf.float32)/255\n",
    "    mask = tf.cast(mask, tf.float32)/255\n",
    "\n",
    "    return img, mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
